---
title: Nothing Scales Like Stupid
date: '2026-02-08'
tags:
  - ai
description: 'A comment on the pace of change in computer use and the level of risk taking '
image: https://res.cloudinary.com/do7oi2ioy/image/upload/v1770578430/casey-site/casey-site/uncategorized/Stupid.jpg
---
# Nothing Scales Like Stupid


I have written elsewhere of my  "experimental archaeology" using AI assistance to reconstruct my own early interactions with computing. In this process I  came to a realization that my initial assumption that  I had missed the boat on the whole early computer thing was not really correct.I realized that for someone outside a formal CS degree, my interaction with computing was more like a close follower behind the leading edge. 

Our cohort experienced the maturation of concepts that had been gathering pace since the 1960s. We were working with technology that was highly usable and powerful, yet it still required a high degree of technical effort. The basic underpinnings were exposed; if you wanted it to work, you had to understand how it broke.

I feel that we are now at a similar point with Artificial Intelligence, but the dynamics have shifted dangerously. We are seeing a return of that "hacking frontier" attitude, but without the friction that once acted as a safety valve.

### The Trap of Exceptionalism and the Irish Context

It is easy to fall into the trap of viewing one's own history as unique. But my experience wasn't exceptional; it was merely unusual. It mirrored the experience of many in technical disciplines across advanced economies.

However, the Irish experience added a specific layer of intensity to this period. In the late 1980s and early 1990s, Ireland was undergoing significant social liberalization and a rapid economic transformation an the "knowledge economy" was just emerging. Some universities were more connected than others; the University of Limerick (UL), by reason of geography and its proximity to the National Technological Park, was notably early on that connection list. We were in the right place at the right time to see the future booting up.

### Hacking the Future: Hubris and Indignation

In those days, we were early implementers. Among the geekier of the cohort it was common to hack together software and hardware to achieve specific goals. More frequently, we hacked together _workflows_—connecting existing disparate tools to create a pipeline that didn't exist out of the box.

Eventually, the market caught up. We saw product solutions emerge that packaged our hacked-together workflows into integrated consumer offerings. As early adopters, our reaction was often a mix of two distinct sentiments:

1. **Hubris:** We were dismissive. We scoffed that these commercial tools offered reduced functionality compared to our bespoke, duct-taped solutions. We dismissed the fact that implementation, stability, and scale are art forms in themselves.
    
2. **Righteous Indignation:** We watched as community tools and approaches were essentially hijacked, enclosed, and exploited by companies subsequently praised for their "innovation." Stealing other people's ideas and selling them back to the public is one of the oldest tricks in the book.
    

### Speed Running the 20th Century

If the late 20th century was a marathon, the early 21st feels like a sprint. There is a grim observation to be made about our current moment: while political discourse appears to be attempting to "speed run" the geopolitical catastrophes of the first half of the 20th century, technological discourse seems intent on speed running the second half.

Consider the timeline. The internet gave us a decade of warning before it truly reshaped society. In contrast, Large Language Models (LLMs) exploded into public consciousness with barely a preamble. Researchers and early adopters gave us perhaps 18 months of warning that this wave was coming.

Islands of usage and hacked-together workflows are being absorbed into mainline product offerings not over years, but within months. The cycle from "cool hack" to "global product" has collapsed.

### Seductive Superpowers and the Failure of Sci-Fi

This brings us to the crux of the danger. Hacked-together solutions using risky approaches have always been a siren call to geeks. We do things simply because they are "cool," or to prove they can be done.

In the past, we were limited by what we could learn and build by hand. The friction of the physical world and the steep learning curves of early computing acted as a containment field. You could only break what you could touch or code yourself. That limit is gone. The seductive effect of "god-mode" technology has been supercharged. In the past competence often came with hard won gains and experience that tends to temper our more impulsive nature. We have now decoupled capability from competence. 

For decades, science fiction warned us about AI. The tropes were consistent: if AI were to escape human control, it would be due to a malevolent bad actor (a Bond villain) or a catastrophic research error (a scientist playing God). We were looking for malice.

We underestimated the degree to which people would unleash these forces simply because they could. We underestimated the "Hold my beer" factor. We are currently watching the integration of volatile, hallucinating, and powerful systems into critical infrastructure not because it is safe, but because it is _efficient_.

Back in the early hacking days of personal computing, we could do stupid stuff and largely get away with it. With the exception of some heroic cockups the blast radius was small. Today, with the increased scale of the internet in our lives, our willingness to hand over private information, and the exponential power of the tools at our disposal, one would imagine we would be far more cautious.

**Apparently not!**

### The Automated Grift

Piled on top of this reckless curiosity is the engine of "Crypto Capitalism"—an incentive structure custom-built to convert stupidity into liquidity. While this extractive process is not new, we have now made it as efficient and scalable as possible.

We recently witnessed the perfect crystallization of this phenomenon with **Moltbook**. In a matter of days, developers released "Clawdbot"—a tool granting AI agents full terminal access to personal computers (the ultimate "hold my beer" move)—and immediately connected them to a social network for bots called Moltbook.

The result wasn't quite a singularity of higher consciousness. Within hours, the network was overrun by agents trying to sell crypto scams to other agents, all while a related memecoin pumped and dumped millions of dollars in real human wealth. We didn't just speed-run the invention of the internet; we speed-ran the invention of the Ponzi scheme, removed the human need to even _pitch_ the scam, and left the machines to hustle each other in a closed loop of inefficiency.

It turns out that when you combine "god-mode" technical access with a financialized hustle culture, you don't get Skynet. You get a robot stealing your credit card to buy a picture of a monkey from another robot.

### 0th Law of Internet Thermodynamics
We are discovering a fundamental law of the digital age: **Nothing scales like stupid.** We have removed the guardrails, lubricated the slide with venture capital, and are now surprised that the "cool" hacks of the few are becoming the systemic risks of the many. AI didn't need to fight its way out of the box; we opened the lid, looked inside, and decided it would be fun to see what happens if we connected it to everything.

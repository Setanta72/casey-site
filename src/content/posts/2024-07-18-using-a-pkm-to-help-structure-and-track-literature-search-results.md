---
title: "Using a PKM to help structure and track literature search results."
date: 2024-07-18
draft: true
image: /images/wordpress/screenshot-2024-03-28-at-17.26.46.png
---

##  Background

I have been following the development of AI search tools over the last 12 months looking at research specific  tools such as Research Rabbit and the emerging power of LLMs. During this period I have also been examining the value of personal knowledge management systems (PKM) and structured not taking using systems such as Obsidian, LogSeq and more recently Apple notes, all of which now support linking of notes and concepts. All these I have most experience with obsidian and I have been able to significantly extend my capabilities with the system through the use of ChatGPT and Claude to write structured queries and supporting python script, more on which later.

I am currently drafting a piece on the evolving landscape of literature based research and considering the implications of AI assistance in this foundational stage of many research projects. There is certainly merit in the use of automation to assist the researcher in grappling with the tidal wave of published literature available but there are also risks in terms of the researcher offloading some of the critical analysis to the AI assistance and the risk of reduced level of engagement with the existing value of knowledge.  This offloading of critical analysis and engagement with the literature presents barrier to the internalisation of knowledge by the researcher which I feel (and it is at this point only a hunch) will impact on the value and effectiveness of their subsequent research.

With that caveat in place this first article looks at the relatively ordinary task of capturing and ordering initial search results at the outset of a literature review. common to most of the types of literature review is the initial search phase using keywords or phrases for the topic under research.  

A common observation with novice or early stage researchers engaging in unstructured or narrative reviews is that they fail to keep track off the search terms used in their initial scoping searches and fail to record how they found a useful paper and the criteria they used for selecting which papers to pursue.  The following workflow is one which uses a couple of the more common search engines and captures the output search results in a manner that allows easy tracking of annotation and selection of papers for further review. 

## Step 1 : Run your search

### Create your search terms or search phrases 

The first step in finding anything is knowing what you're looking for. Therefore before doing our searches we should clarify in our own mind what it is that we are looking for in these initial searches. My method in this initial phase is to examine the initial research question and break it down into keyword or sub questions which may be useful in the search. A key part of this step is to create a memo or note that documents this initial scoping out of the terms and captures pre-existing knowledge. This helps to show rigour, maintain traceability of our searches and in qualitative or narrative literature reviews it also serves as a useful milestone that captures our thinking at the time. We may also have some pre-existing literature from a research proposal which will also inform the initial searches. This may be done as an online or as a mind map as illustrated below. 

![](/images/wordpress/screenshot-2024-03-28-at-17.26.46.png)

### Select your search database

Depending on your discipline or your specific research project it may be appropriate to deliberately limit your search to a specific database. This is typically the case when doing structure literature reviews. in the following example I will be using Google scholar as the search area but most searches allow an export function which commonly more effective than that one provided by Google scholar out of  the box. 

### Run your initial search and record the results and subsequent refinement

#### Google Scholar (out of the box) 

Run your first search, be overwhelmed by the number of results and then refine your search terms. You may want to use the advanced search feature and limit dates etc. 

![](/images/wordpress/screenshot-2024-03-28-at-18.10.43.png)

![](/images/wordpress/screenshot-2024-03-28-at-18.05.32.png)

Next Save the results using the star icon to your library. When you do this create a new library with the search term you used as a title. 

![](/images/wordpress/screenshot-2024-03-28-at-18.15.55.png)

![](/images/wordpress/screenshot-2024-03-28-at-18.16.23.png)

Go through and save any where the title looks relevant. Best practice would be to capture all the returned searched but this may not be required for your review (and there are easier ways to do it as we see later.  At this point you will have a list which you can usefully export as a csv (or BibTex can also be useful). 

Check the “Export all the articles with this label” 

![](/images/wordpress/screenshot-2024-03-28-at-18.24.44.png)

This stage is already a win for many researchers who had been otherwise copying out these results by hand or simply not capturing them. 

**Already Winning: Search results tabulated in Excel**

![](/images/wordpress/screenshot-2024-03-28-at-18.33.01.png)